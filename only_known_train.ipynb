{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.basic_data import *\n",
    "from skimage.util import montage\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take a curriculum approach to training here. I first expose the model to as many different images of whales as quickly as possible (no oversampling) and train on images resized to 224x224.\n",
    "\n",
    "I would like the conv layers to start picking up on features useful for identifying whales. For that, I want to show the model as rich of a dataset as possible.\n",
    "\n",
    "I then train on images resized to 448x448.\n",
    "\n",
    "Finally, I train on oversampled data. Here, the model will see some images more often than others but I am hoping that this will help alleviate the class imbalance in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastprogress import force_console_behavior\n",
    "import fastprogress\n",
    "fastprogress.fastprogress.NO_BAR = True\n",
    "master_bar, progress_bar = force_console_behavior()\n",
    "fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "val_fns = {'69823499d.jpg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn2label = {row[1].Image: row[1].Id for row in df.iterrows()}\n",
    "path2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'res50-full-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224\n",
    "BS = 64\n",
    "NUM_WORKERS = 12\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], 'data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('data/test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         7.457255    0.708407    \n",
      "2         6.666923    0.078581    \n",
      "3         6.077693    0.093856    \n",
      "4         5.138601    0.014386    \n",
      "5         4.253701    2.648608    \n",
      "6         3.402944    1.789264    \n",
      "7         2.651533    0.005592    \n",
      "8         1.863626    0.000208    \n",
      "9         1.186273    0.012435    \n",
      "10        0.684969    0.000092    \n",
      "11        0.384233    0.000017    \n",
      "12        0.225224    0.000001    \n",
      "13        0.141565    0.000004    \n",
      "14        0.111797    0.000007    \n",
      "epoch     train_loss  valid_loss\n",
      "1         0.096187    0.000008    \n",
      "2         0.121451    0.000062    \n",
      "3         0.160986    0.000025    \n",
      "4         0.242702    0.000004    \n",
      "5         0.267682    0.000053    \n",
      "6         0.314039    0.000002    \n",
      "7         0.327478    0.000000    \n",
      "8         0.302776    0.001108    \n",
      "9         0.269261    0.000341    \n",
      "10        0.239256    0.000433    \n",
      "11        0.201479    0.002558    \n",
      "12        0.171274    0.000002    \n",
      "13        0.149561    0.000000    \n",
      "14        0.135921    0.000027    \n",
      "15        0.113643    0.000001    \n",
      "16        0.094750    0.000456    \n",
      "17        0.074803    0.000000    \n",
      "18        0.055229    0.000000    \n",
      "19        0.045535    0.000002    \n",
      "20        0.037293    0.000000    \n",
      "21        0.037641    0.000000    \n",
      "22        0.031186    0.000000    \n",
      "23        0.031796    0.000000    \n",
      "24        0.032020    0.000000    \n",
      "CPU times: user 37min 36s, sys: 14min 15s, total: 51min 51s\n",
      "Wall time: 55min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048])\n",
    "learn.clip_grad();\n",
    "\n",
    "learn.fit_one_cycle(14, 1e-2)\n",
    "learn.save(f'{name}-stage-1')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(24, lrs)\n",
    "learn.save(f'{name}-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224 * 2\n",
    "BS = 64 // 4\n",
    "NUM_WORKERS = 12\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], 'data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('data/test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         1.100031    0.000000    \n",
      "3         1.335055    0.000000    \n",
      "4         1.674122    0.000000    \n",
      "5         1.785136    0.000000    \n",
      "6         1.717228    0.000000    \n",
      "7         1.412960    0.000000    \n",
      "8         1.303269    0.000000    \n",
      "9         1.008257    0.000000    \n",
      "10        0.796222    0.000000    \n",
      "11        0.634087    0.000000    \n",
      "12        0.487326    0.000000    \n",
      "epoch     train_loss  valid_loss\n",
      "1         0.482283    0.000000    \n",
      "2         0.492100    0.000000    \n",
      "3         0.563699    0.000000    \n",
      "4         0.571843    0.000000    \n",
      "5         0.650438    0.000000    \n",
      "6         0.695321    0.000000    \n",
      "7         0.700596    0.000000    \n",
      "8         0.615317    0.000000    \n",
      "9         0.678798    0.000000    \n",
      "10        0.616675    0.000000    \n",
      "11        0.715437    0.000000    \n",
      "12        0.628833    0.000000    \n",
      "13        0.616170    0.000000    \n",
      "14        0.530670    0.000000    \n",
      "15        0.458034    0.000000    \n",
      "16        0.467264    0.000000    \n",
      "17        0.390240    0.000000    \n",
      "18        0.413110    0.000000    \n",
      "19        0.381089    0.000000    \n",
      "20        0.356445    0.000000    \n",
      "21        0.345979    0.000000    \n",
      "22        0.378644    0.000000    \n",
      "CPU times: user 2h 2min 35s, sys: 53min 23s, total: 2h 55min 59s\n",
      "Wall time: 2h 57min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048])\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-2')\n",
    "learn.freeze_to(-1)\n",
    "\n",
    "learn.fit_one_cycle(12, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-3')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(22, lrs)\n",
    "learn.save(f'{name}-stage-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with oversampling\n",
    "df = pd.read_csv('data/oversampled_train_and_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df, 'data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('data/test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         1.626801    0.000010    \n",
      "2         0.566748    0.000010    \n",
      "epoch     train_loss  valid_loss\n",
      "1         0.604931    0.000121    \n",
      "2         0.531284    0.000026    \n",
      "3         0.442735    0.000039    \n",
      "CPU times: user 1h 25min 46s, sys: 38min 1s, total: 2h 3min 48s\n",
      "Wall time: 2h 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048])\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-4')\n",
    "learn.freeze_to(-1)\n",
    "\n",
    "learn.fit_one_cycle(2, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-5')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(3, lrs)\n",
    "learn.save(f'{name}-stage-6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat((preds, torch.ones_like(preds[:, :1])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:, 5004] = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = learn.data.classes + ['new_whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(preds, learn.data, name, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47380533f.jpg</td>\n",
       "      <td>w_6c995fd new_whale w_7206ab2 w_54ea24d w_620dffe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1d9de38ba.jpg</td>\n",
       "      <td>w_641df87 new_whale w_e99ed06 w_3e6cee1 w_0b7ce1e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b3d4ee916.jpg</td>\n",
       "      <td>new_whale w_23ce00e w_bc7de9f w_71a1a08 w_708c3d2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>460fd63ae.jpg</td>\n",
       "      <td>new_whale w_0bb71d3 w_9eab46a w_60cf87c w_42388df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79738ffc1.jpg</td>\n",
       "      <td>new_whale w_1419d90 w_01976db w_dbf651b w_415dea0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image                                                 Id\n",
       "0  47380533f.jpg  w_6c995fd new_whale w_7206ab2 w_54ea24d w_620dffe\n",
       "1  1d9de38ba.jpg  w_641df87 new_whale w_e99ed06 w_3e6cee1 w_0b7ce1e\n",
       "2  b3d4ee916.jpg  new_whale w_23ce00e w_bc7de9f w_71a1a08 w_708c3d2\n",
       "3  460fd63ae.jpg  new_whale w_0bb71d3 w_9eab46a w_60cf87c w_42388df\n",
       "4  79738ffc1.jpg  new_whale w_1419d90 w_01976db w_dbf651b w_415dea0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'subs/{name}.csv.gz').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48693467336683416"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'subs/{name}.csv.gz').Id.str.split().apply(lambda x: x[0] == 'new_whale').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 183k/183k [00:04<00:00, 37.6kB/s]\n",
      "Successfully submitted to Humpback Whale Identification"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c humpback-whale-identification -f subs/{name}.csv.gz -m \"{name}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
